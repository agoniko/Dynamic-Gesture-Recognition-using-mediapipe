{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dataset = \"./data/labels/1 label dataset.json\"\n",
    "values_dataset = \"./data/values/1 values dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_list = json.load(open(values_dataset))\n",
    "timestamps = [float(x) for x in list(landmark_list.keys())]\n",
    "\n",
    "#loading labels from the key_log.txt file with format: timestamp,key\n",
    "labels = json.load(open(labels_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 4796, 4796)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), len(timestamps), len(landmark_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4796, 21, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "values = []\n",
    "for val in landmark_list.values():\n",
    "    values.append(list(val.values()))\n",
    "\n",
    "values = np.array(values)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1594, 14, 21, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "window_size = 14\n",
    "overlap = 3\n",
    "for i in range(0, len(values) - window_size, overlap):\n",
    "    data.append(values[i:i+window_size])\n",
    "\n",
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training autoencoder for self-supervised learning (easy way)\n",
    "### This helps learning representation of dynamic gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 14, 21, 3)]       0         \n",
      "                                                                 \n",
      " model_9 (Functional)        (None, 7, 7, 32)          5088      \n",
      "                                                                 \n",
      " model_10 (Functional)       (None, 14, 21, 3)         5059      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10147 (39.64 KB)\n",
      "Trainable params: 10147 (39.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_shape = Input(shape=(window_size, 21, 3))\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "encoded = Conv2D(32, (3, 3), activation='relu', padding='same', name = \"encoder\")(x)\n",
    "encoder_model = Model(input_shape, encoded)\n",
    "\n",
    "decoder_input = Input(shape = (encoder_model.output_shape[1:]))\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(decoder_input)\n",
    "x = UpSampling2D((2, 3))(decoder_input)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((1, 1))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "decoder_model = Model(decoder_input, decoded)\n",
    "\n",
    "encoded_representation = encoder_model(input_shape)\n",
    "decoded_output = decoder_model(encoded_representation)\n",
    "autoencoder = Model(inputs=input_shape, outputs=decoded_output)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:27:39.948519: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 2s 25ms/step - loss: 0.3278 - val_loss: 0.1293\n",
      "Epoch 2/30\n",
      " 1/45 [..............................] - ETA: 0s - loss: 0.1891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:27:41.205154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 16ms/step - loss: 0.1650 - val_loss: 0.0956\n",
      "Epoch 3/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1417 - val_loss: 0.0838\n",
      "Epoch 4/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1355 - val_loss: 0.0806\n",
      "Epoch 5/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1331 - val_loss: 0.0787\n",
      "Epoch 6/30\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.1319 - val_loss: 0.0767\n",
      "Epoch 7/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1309 - val_loss: 0.0761\n",
      "Epoch 8/30\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.1301 - val_loss: 0.0757\n",
      "Epoch 9/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1341 - val_loss: 0.0785\n",
      "Epoch 10/30\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.1318 - val_loss: 0.0758\n",
      "Epoch 11/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1296 - val_loss: 0.0756\n",
      "Epoch 12/30\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.1294 - val_loss: 0.0755\n",
      "Epoch 13/30\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.1290 - val_loss: 0.0751\n",
      "Epoch 14/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1285 - val_loss: 0.0745\n",
      "Epoch 15/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1294 - val_loss: 0.0742\n",
      "Epoch 16/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1298 - val_loss: 0.0754\n",
      "Epoch 17/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1279 - val_loss: 0.0751\n",
      "Epoch 18/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1520 - val_loss: 0.1024\n",
      "Epoch 19/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1424 - val_loss: 0.0801\n",
      "Epoch 20/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1335 - val_loss: 0.0781\n",
      "Epoch 21/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1518 - val_loss: 0.1034\n",
      "Epoch 22/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1637 - val_loss: 0.0931\n",
      "Epoch 23/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1441 - val_loss: 0.0867\n",
      "Epoch 24/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1380 - val_loss: 0.0807\n",
      "Epoch 25/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1319 - val_loss: 0.0784\n",
      "Epoch 26/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1318 - val_loss: 0.1174\n",
      "Epoch 27/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1350 - val_loss: 0.0775\n",
      "Epoch 28/30\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.1358 - val_loss: 0.0784\n",
      "Epoch 29/30\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.1462 - val_loss: 0.0853\n",
      "Epoch 30/30\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.1366 - val_loss: 0.0795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29c77ac90>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(data, data, epochs=30, batch_size=32, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning the encoder model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "for layer in encoder_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "additional_layers = Sequential([\n",
    "    Input(shape = (encoder_model.output_shape[1:])),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation='sigmoid')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_9 (Functional)        (None, 7, 7, 32)          5088      \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 4)                 873252    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 878340 (3.35 MB)\n",
      "Trainable params: 873252 (3.33 MB)\n",
      "Non-trainable params: 5088 (19.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([encoder_model, additional_layers])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = json.load(open(labels_dataset, \"r\"))\n",
    "\n",
    "#Now, from landmark_list, we want to extract a window of 0.5 seconds before and after each key press\n",
    "#We will use the labels dictionary to label each window\n",
    "#We will use the timestamps list to find the closest timestamp to the key press timestamp\n",
    "#We will use the freq variable to calculate the number of frames we need to extract for each window\n",
    "#We will use the loaded_landmark_list to extract the frames\n",
    "window_size = 0.5  #0.5 seconds before and after the key press\n",
    "freq = 14 #14 frames per second\n",
    "window_frames = int(freq * window_size)\n",
    "X, Y = [], []\n",
    "for key in labels.keys():\n",
    "    key = float(key)\n",
    "    closest_timestamp = min(timestamps, key=lambda x:abs(x-key))\n",
    "    index = timestamps.index(closest_timestamp)\n",
    "    if index - window_frames < 0:\n",
    "        continue\n",
    "    if index + window_frames >= len(timestamps):\n",
    "        continue\n",
    "    \n",
    "    window = []\n",
    "    for i in range(index-window_frames, index+window_frames):\n",
    "        k = str(timestamps[i])\n",
    "        window.append(landmark_list[k])\n",
    "\n",
    "    X.append(window)\n",
    "    Y.append(labels[str(key)])\n",
    "\n",
    "#retrive a structure with shape (n_windows, window_size, 21, 3)\n",
    "data2 = []\n",
    "for window in X:\n",
    "    temp = []\n",
    "    for sample in window:\n",
    "        temp.append(np.array(list(sample.values())))\n",
    "    \n",
    "    data2.append(np.array(temp))\n",
    "\n",
    "data = np.array(data2)\n",
    "del data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#Y = [1 if y == 'Key.left' else 0 for y in Y]\n",
    "Y = np.array(Y)\n",
    "encoder = OneHotEncoder()\n",
    "Y_encoded = encoder.fit_transform(Y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, Y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/6 [====>.........................] - ETA: 2s - loss: 1.3746 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:28:21.342919: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 63ms/step - loss: 0.8847 - accuracy: 0.7622 - val_loss: 0.6677 - val_accuracy: 0.8421\n",
      "Epoch 2/30\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.4395 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:28:21.740348: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4308 - accuracy: 0.8963 - val_loss: 0.3293 - val_accuracy: 0.8421\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3095 - accuracy: 0.9024 - val_loss: 0.2849 - val_accuracy: 0.8421\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3101 - accuracy: 0.9268 - val_loss: 0.1785 - val_accuracy: 0.8947\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2394 - accuracy: 0.9329 - val_loss: 0.1103 - val_accuracy: 0.9474\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2133 - accuracy: 0.9512 - val_loss: 0.0997 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1938 - accuracy: 0.9695 - val_loss: 0.0949 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1788 - accuracy: 0.9573 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1547 - accuracy: 0.9695 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1549 - accuracy: 0.9695 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1562 - accuracy: 0.9817 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1550 - accuracy: 0.9817 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1333 - accuracy: 0.9756 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1301 - accuracy: 0.9817 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1211 - accuracy: 0.9817 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1214 - accuracy: 0.9817 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1081 - accuracy: 0.9817 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1123 - accuracy: 0.9817 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1084 - accuracy: 0.9756 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1009 - accuracy: 0.9817 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0987 - accuracy: 0.9817 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0920 - accuracy: 0.9817 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0885 - accuracy: 0.9817 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0907 - accuracy: 0.9817 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2097 - accuracy: 0.9573 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1523 - accuracy: 0.9573 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1004 - accuracy: 0.9817 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0842 - accuracy: 0.9878 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0801 - accuracy: 0.9878 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0792 - accuracy: 0.9878 - val_loss: 0.0085 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x35a650490>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=32, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x3615beca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:28:27.559341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46, 4), (46, 4))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0,  0],\n",
       "       [ 0, 14,  0,  0],\n",
       "       [ 0,  0, 27,  0],\n",
       "       [ 0,  0,  0,  4]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(y_test.argmax(axis = 1), y_pred.argmax(axis=1), average='weighted')\n",
    "recall = recall_score(y_test.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "f1 = f1_score(y_test.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:25:08.211723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-20 17:25:08.395031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/11 [====>.........................] - ETA: 0s - loss: 1.6577 - accuracy: 0.3125 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:25:08.600205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 1.7204 - accuracy: 0.4878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:25:09.602691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-20 17:25:09.680134: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 109ms/step - loss: 1.7204 - accuracy: 0.4878 - val_loss: 1.5526 - val_accuracy: 0.8421\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.7733 - accuracy: 0.8598 - val_loss: 0.5312 - val_accuracy: 0.8947\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.4703 - accuracy: 0.9207 - val_loss: 0.3304 - val_accuracy: 0.8421\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.3235 - accuracy: 0.9024 - val_loss: 0.2759 - val_accuracy: 0.8421\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.3069 - accuracy: 0.9329 - val_loss: 0.2135 - val_accuracy: 0.9474\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2903 - accuracy: 0.9024 - val_loss: 0.2487 - val_accuracy: 0.8421\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.2647 - accuracy: 0.9207 - val_loss: 0.2002 - val_accuracy: 0.8947\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.2342 - accuracy: 0.9329 - val_loss: 0.1177 - val_accuracy: 0.9474\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2205 - accuracy: 0.9390 - val_loss: 0.1231 - val_accuracy: 0.9474\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.2175 - accuracy: 0.9390 - val_loss: 0.1281 - val_accuracy: 0.9474\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.2254 - accuracy: 0.9451 - val_loss: 0.1277 - val_accuracy: 0.9474\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2294 - accuracy: 0.9268 - val_loss: 0.1778 - val_accuracy: 0.9474\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2108 - accuracy: 0.9451 - val_loss: 0.1297 - val_accuracy: 0.9474\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2204 - accuracy: 0.9390 - val_loss: 0.1154 - val_accuracy: 0.9474\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.2763 - accuracy: 0.9268 - val_loss: 0.1039 - val_accuracy: 0.9474\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.3120 - accuracy: 0.9207 - val_loss: 0.2294 - val_accuracy: 0.8421\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2348 - accuracy: 0.9329 - val_loss: 0.0958 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2060 - accuracy: 0.9634 - val_loss: 0.1257 - val_accuracy: 0.9474\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.2835 - accuracy: 0.9512 - val_loss: 0.0907 - val_accuracy: 0.9474\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.2391 - accuracy: 0.9451 - val_loss: 0.1458 - val_accuracy: 0.9474\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.2525 - accuracy: 0.9329 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.3826 - accuracy: 0.9268 - val_loss: 0.1316 - val_accuracy: 0.9474\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.3811 - accuracy: 0.9329 - val_loss: 0.6108 - val_accuracy: 0.8947\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.5643 - accuracy: 0.9207 - val_loss: 0.6631 - val_accuracy: 0.8947\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.5426 - accuracy: 0.9268 - val_loss: 0.5643 - val_accuracy: 0.8947\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.3447 - accuracy: 0.9390 - val_loss: 0.0969 - val_accuracy: 0.9474\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.2169 - accuracy: 0.9390 - val_loss: 0.0968 - val_accuracy: 0.9474\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2081 - accuracy: 0.9451 - val_loss: 0.0876 - val_accuracy: 0.9474\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.2061 - accuracy: 0.9512 - val_loss: 0.1224 - val_accuracy: 0.8947\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2064 - accuracy: 0.9573 - val_loss: 0.1069 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29ca5d910>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv3D, MaxPooling2D, Flatten, Reshape, LSTM, Dense, Conv2D, Concatenate\n",
    "num_classes = set(Y).__len__()\n",
    "inp_shape = data.shape[1:]\n",
    "\n",
    "# Input shape: (n_samples, 14, 21, 3)\n",
    "input = Input(shape=inp_shape)\n",
    "x = Conv2D(8, (2, 2), activation='relu', padding='same')(input)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "x = Conv2D(16, (2, 2), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "\n",
    "y = Reshape((inp_shape[0]*inp_shape[1], inp_shape[2]))(input)\n",
    "y = LSTM(16, return_sequences=True)(y)\n",
    "y = Flatten()(y)\n",
    "y = Dense(192, activation='relu')(y)\n",
    "y = Reshape((4, 3, 16))(y)\n",
    "y = Concatenate()([x, y])\n",
    "y = Flatten()(y)\n",
    "y = Dense(64, activation='relu')(y)\n",
    "y = Dense(16, activation='relu')(y)\n",
    "y = Dense(4, activation='softmax')(y)\n",
    "model = Model(input, y)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:25:27.982972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-20 17:25:28.043809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.968167701863354\n",
      "Recall:  0.9565217391304348\n",
      "F1:  0.9530961791831356\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "recall = recall_score(y_test.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "f1 = f1_score(y_test.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5823341"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6264\n",
    "5823341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
